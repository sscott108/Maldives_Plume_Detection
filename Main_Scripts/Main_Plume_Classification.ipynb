{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet_pretrained = resnet50(pretrained=True)\n",
    "        self.resnet_pretrained.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3),\n",
    "                              stride=(2, 2),padding=(3, 3), bias=False)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.resnet_pretrained.fc.out_features, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)  # output size changed to 2\n",
    "        self.dropout = nn.Dropout(p=0.15)\n",
    "    def forward(self, image):\n",
    "        img_features = self.resnet_pretrained(image)\n",
    "        img_features = torch.flatten(img_features, 1)\n",
    "        img_features = self.fc1(img_features)\n",
    "        x = self.relu(img_features)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss, opt, dataloader):\n",
    "    model.train()\n",
    "    train_loss_total, train_acc_total = 0, 0\n",
    "    progress = tqdm(enumerate(dataloader), desc=\"Train Loss: \", total=len(dataloader))\n",
    "    \n",
    "    for i, batch in enumerate(dataloader):\n",
    "        x = batch['img'].float()\n",
    "        y = batch['lbl'].unsqueeze(1).to(torch.float64)\n",
    "        output = model(x)\n",
    "        print(output)\n",
    "#         predictions = torch.argmax(output, axis=1).unsqueeze(dim=1)        # Calculate loss\n",
    "        output_binary = np.zeros(output.shape)\n",
    "        output_binary[output.cpu().detach().numpy() >= 0] = 1\n",
    "        \n",
    "        # Derive accuracy score\n",
    "        label = y.cpu().detach().numpy()\n",
    "        acc = accuracy_score(label, output_binary)\n",
    "        print(label)\n",
    "        print(acc)\n",
    "        train_acc_total += acc\n",
    "\n",
    "        # Calculate loss\n",
    "        loss_epoch = loss(output, y.reshape(-1, 1))\n",
    "        train_loss_total += loss_epoch.item()\n",
    "        progress.set_description(\"Train Loss: {:.4f}\".format(train_loss_total / (i + 1)))\n",
    "\n",
    "        \n",
    "        # Learning\n",
    "        opt.zero_grad()\n",
    "        loss_epoch.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return train_loss_total/len(dataloader), train_acc_total/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loss, dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    test_loss_total, test_acc_total = 0, 0\n",
    "    test_label_total, test_pred_total = [], []\n",
    "    progress = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    with torch.no_grad():\n",
    "        for k, batch in progress:\n",
    "            x, y = batch['img'].float(), batch['lbl'].unsqueeze(1).to(torch.float64)\n",
    "            output = model(x)\n",
    "\n",
    "            predictions = torch.argmax(output, axis=1).unsqueeze(dim=1)  \n",
    "            \n",
    "            # Calculate loss\n",
    "            loss_epoch = loss(predictions.float(), y).requires_grad_()\n",
    "            test_loss_total += loss_epoch.item()\n",
    "            progress.set_description(\"Test Loss: {:.4f}\".format(test_loss_total / (k + 1)))\n",
    "\n",
    "            # Derive binary output\n",
    "            output_binary = np.zeros(output.shape)\n",
    "            output_binary[output.cpu().detach().numpy() >= 0] = 1\n",
    "            label = y.cpu().detach().numpy()\n",
    "\n",
    "            test_pred_total += list(output_binary[:, 0])\n",
    "            test_label_total += list(label)\n",
    "\n",
    "            # Derive accuracy score\n",
    "            acc = accuracy_score(y.cpu().detach().numpy(), predictions)\n",
    "            test_acc_total += acc\n",
    "    return test_loss_total/len(dataloader), test_acc_total/len(dataloader), test_label_total, test_pred_total, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs, batch_size):\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     model.cuda()\n",
    "    opt = optim.SGD(model.parameters(), lr=1e-5, momentum=0.9880160542000381)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, 'min',\n",
    "                                                factor=0.5, threshold=1e-4,\n",
    "                                                min_lr=1e-6)\n",
    "    loss_train, loss_test, train_acc,test_acc =[],[],[],[]\n",
    "    epoch_table = pd.DataFrame()\n",
    "    # Create datasets\n",
    "    data_pos = create_dataset(datadir= '/hpc/home/srs108/thilafushi/none_sorted_images/positive')\n",
    "    data_neg = create_dataset(datadir= '/hpc/home/srs108/thilafushi/none_sorted_images/negative')\n",
    "    data_all =  torch.utils.data.ConcatDataset([data_pos, data_neg])\n",
    "\n",
    "    # # Initialize data loaders\n",
    "    train_data, test_data = train_test_split(data_all, test_size=0.2, random_state=42)\n",
    "    train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_dl = DataLoader(train_data, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "    val_dl = DataLoader(val_data, batch_size=batch_size)\n",
    "    test_dl = DataLoader(test_data, batch_size=batch_size)\n",
    "    best_acc = 0\n",
    "    for epoch in range(epochs):\n",
    "        #Training \n",
    "        train_loss, train_acc = train(model, loss, opt, train_dl)\n",
    "            \n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Val\n",
    "#         val_loss, val_acc, val_label_total, val_pred_total, k = test(model, loss, val_dl)\n",
    "        \n",
    "#         print((\"Epoch {:d}: train loss={:.3f}, test loss= {:.3f}, \"\n",
    "#                \"train acc={:.3f}, test acc={:.3f}\").format(\n",
    "#                    epoch + 1, train_loss, val_loss,\n",
    "#                    train_acc, val_acc))\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "#         if val_acc > best_acc:\n",
    "#             print(f\"Improved Accuracy: {val_acc}\")\n",
    "#             best_acc = val_acc\n",
    "#             best_model_weights = model.state_dict()\n",
    "#             torch.save(model.state_dict(), 'best_model_weights.pt')\n",
    "\n",
    "        # Generate confusion matrix\n",
    "#         if epoch == epochs - 1:\n",
    "#             array = confusion_matrix(np.array(val_label_total), np.array(val_pred_total))\n",
    "#             cm = pd.DataFrame(array, range(2), range(2))\n",
    "#             svm = sns.heatmap(cm, annot=True)\n",
    "#             figure = svm.get_figure()\n",
    "# #             image_dir = \"../images/test\"\n",
    "#             figure.savefig(f\"conf_matrix.png\")\n",
    "\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "#         epoch_table['epoch'] = epoch\n",
    "#         epoch_table[\"training loss\"] = train_loss\n",
    "#         epoch_table[\"training accuracy\"] = train_acc\n",
    "#         epoch_table[\"val loss\"] = val_loss\n",
    "#         epoch_table[\"val accuracy\"] = val_acc\n",
    "    \n",
    "#     #Testing\n",
    "#     model.load_state_dict(torch.load('best_model_weights.pt'))\n",
    "#     test_loss, test_acc, test_label_total, test_pred_total, k = test(model, loss, test_dl)\n",
    "\n",
    "    print(f\"Testing Accuracy: {test_acc}\")\n",
    "    print(f\"Testing Loss: {test_loss}\")\n",
    "    return model, epoch_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ab81c2bc3d34f15ad2d2fbfc8cca484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train Loss: ', max=25.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0085],\n",
      "        [-0.1586],\n",
      "        [-0.1427],\n",
      "        [-0.1097],\n",
      "        [-0.1721],\n",
      "        [-0.0020],\n",
      "        [-0.3345],\n",
      "        [-0.0565],\n",
      "        [ 0.0095],\n",
      "        [ 0.0364],\n",
      "        [-0.0173],\n",
      "        [-0.0740],\n",
      "        [-0.0806],\n",
      "        [-0.1837],\n",
      "        [-0.1933],\n",
      "        [-0.1018]], grad_fn=<AddmmBackward0>)\n",
      "[[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]]\n",
      "0.5625\n",
      "tensor([[-0.0906],\n",
      "        [ 0.0683],\n",
      "        [ 0.0083],\n",
      "        [-0.0122],\n",
      "        [-0.1450],\n",
      "        [-0.0262],\n",
      "        [-0.2383],\n",
      "        [-0.3058],\n",
      "        [-0.0969],\n",
      "        [-0.1406],\n",
      "        [-0.2715],\n",
      "        [-0.0711],\n",
      "        [-0.0895],\n",
      "        [-0.2079],\n",
      "        [-0.0860],\n",
      "        [-0.1150]], grad_fn=<AddmmBackward0>)\n",
      "[[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "0.25\n",
      "tensor([[-0.0390],\n",
      "        [-0.1638],\n",
      "        [-0.0355],\n",
      "        [ 0.0624],\n",
      "        [-0.0731],\n",
      "        [-0.1812],\n",
      "        [-0.2470],\n",
      "        [-0.1085],\n",
      "        [ 0.0318],\n",
      "        [-0.0160],\n",
      "        [-0.2410],\n",
      "        [-0.1039],\n",
      "        [-0.0992],\n",
      "        [-0.0192],\n",
      "        [-0.1050],\n",
      "        [-0.1451]], grad_fn=<AddmmBackward0>)\n",
      "[[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]]\n",
      "0.375\n",
      "tensor([[-0.0392],\n",
      "        [-0.1250],\n",
      "        [-0.0416],\n",
      "        [ 0.0743],\n",
      "        [-0.1540],\n",
      "        [-0.0878],\n",
      "        [-0.0745],\n",
      "        [-0.1177],\n",
      "        [-0.0917],\n",
      "        [-0.1219],\n",
      "        [-0.0932],\n",
      "        [-0.0944],\n",
      "        [ 0.0097],\n",
      "        [-0.1057],\n",
      "        [-0.2728],\n",
      "        [-0.0992]], grad_fn=<AddmmBackward0>)\n",
      "[[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "0.5\n",
      "tensor([[-0.0564],\n",
      "        [-0.0555],\n",
      "        [-0.0368],\n",
      "        [-0.0333],\n",
      "        [-0.0469],\n",
      "        [-0.1377],\n",
      "        [-0.1853],\n",
      "        [-0.0090],\n",
      "        [-0.1279],\n",
      "        [ 0.0324],\n",
      "        [-0.0657],\n",
      "        [-0.0446],\n",
      "        [-0.1944],\n",
      "        [-0.0631],\n",
      "        [-0.0510],\n",
      "        [-0.1225]], grad_fn=<AddmmBackward0>)\n",
      "[[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "0.5\n",
      "tensor([[-0.0878],\n",
      "        [-0.1370],\n",
      "        [-0.1191],\n",
      "        [-0.1033],\n",
      "        [-0.0427],\n",
      "        [-0.0233],\n",
      "        [-0.1108],\n",
      "        [-0.1583],\n",
      "        [ 0.0379],\n",
      "        [-0.0790],\n",
      "        [-0.1048],\n",
      "        [-0.1501],\n",
      "        [-0.0078],\n",
      "        [-0.0960],\n",
      "        [-0.1950],\n",
      "        [-0.2218]], grad_fn=<AddmmBackward0>)\n",
      "[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]]\n",
      "0.5625\n",
      "tensor([[ 0.0321],\n",
      "        [-0.1158],\n",
      "        [-0.3137],\n",
      "        [-0.1751],\n",
      "        [-0.1251],\n",
      "        [-0.1407],\n",
      "        [ 0.0347],\n",
      "        [-0.0776],\n",
      "        [-0.2644],\n",
      "        [-0.1178],\n",
      "        [-0.2047],\n",
      "        [-0.0382],\n",
      "        [-0.0820],\n",
      "        [ 0.0371],\n",
      "        [ 0.0144],\n",
      "        [-0.0762]], grad_fn=<AddmmBackward0>)\n",
      "[[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]]\n",
      "0.4375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-db3b5f27fd4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Run time: {( time.time() - start)/3600}h\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-d5dff20cabbc>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, epochs, batch_size)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m#Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-29273af98cd9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loss, opt, dataloader)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lbl'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#         predictions = torch.argmax(output, axis=1).unsqueeze(dim=1)        # Calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5918342c142a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mimg_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mimg_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mimg_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    459\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 460\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run model training\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "model = CNN()\n",
    "epochs = 200\n",
    "batch_size = 16\n",
    "start = time.time()\n",
    "trained_model, epoch_table = train_model(model, epochs, batch_size)\n",
    "\n",
    "print(f\"Run time: {( time.time() - start)/3600}h\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 'epoch' column as index\n",
    "epoch_table = epoch_table.set_index(\"epoch\")\n",
    "\n",
    "# Convert training and test accuracy values to percentages\n",
    "epoch_table['training accuracy'] = epoch_table['training accuracy']*100\n",
    "epoch_table['test accuracy'] = epoch_table['test accuracy']*100\n",
    "\n",
    "# Round all values in the DataFrame to two decimal places\n",
    "epoch_table = epoch_table.apply(lambda x: round(x, 2))\n",
    "\n",
    "# Visualize the table\n",
    "epoch_table.style.background_gradient(cmap='Blues').set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f15f1c6bf90>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and testing accuracy\n",
    "epoch_table_acc = epoch_table[['training accuracy','val accuracy']]\n",
    "acc_plot = sns.relplot(data=epoch_table_acc, kind=\"line\")\n",
    "acc_plot.set(ylabel=\"accuracy\",title = \"Training and Validation Accuracy\")\n",
    "plt.savefig(\"accuracy.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and testing loss\n",
    "epoch_table_loss = epoch_table[['training loss','val loss']]\n",
    "acc_plot = sns.relplot(data=epoch_table_loss, kind=\"line\")\n",
    "# acc_plot.set(ylabel=\"loss\",title = \"Training and Validation Loss\")\n",
    "# plt.savefig(\"loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
