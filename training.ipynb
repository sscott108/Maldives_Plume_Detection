{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "from math import floor ,log10\n",
    "from torch import nn, optim\n",
    "from tqdm.autonotebook import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import argparse\n",
    "from sklearn.metrics import roc_curve, confusion_matrix\n",
    "import warnings\n",
    "import torch.nn.functional as nnf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import rasterio as rio\n",
    "import time \n",
    "from torchvision.models import resnet50\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/hpc/home/srs108/history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_iou</th>\n",
       "      <th>val_iou</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.190840</td>\n",
       "      <td>1.133607</td>\n",
       "      <td>0.056460</td>\n",
       "      <td>0.043494</td>\n",
       "      <td>0.968877</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.164949</td>\n",
       "      <td>1.119090</td>\n",
       "      <td>0.056205</td>\n",
       "      <td>0.044043</td>\n",
       "      <td>0.969616</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.128882</td>\n",
       "      <td>1.075146</td>\n",
       "      <td>0.054092</td>\n",
       "      <td>0.040056</td>\n",
       "      <td>0.969139</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.094905</td>\n",
       "      <td>1.027226</td>\n",
       "      <td>0.040842</td>\n",
       "      <td>0.022111</td>\n",
       "      <td>0.967611</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.054504</td>\n",
       "      <td>0.990963</td>\n",
       "      <td>0.013751</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>0.967917</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.024019</td>\n",
       "      <td>0.966123</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.968186</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.013201</td>\n",
       "      <td>0.949408</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.967312</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.994900</td>\n",
       "      <td>0.938894</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968209</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.989056</td>\n",
       "      <td>0.932630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968117</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.991728</td>\n",
       "      <td>0.928633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.967380</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.992222</td>\n",
       "      <td>0.926200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.967071</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.977041</td>\n",
       "      <td>0.924447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968646</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.982640</td>\n",
       "      <td>0.923357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.967895</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.983979</td>\n",
       "      <td>0.922585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.967659</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.979320</td>\n",
       "      <td>0.922015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968123</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.921600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.965773</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.978220</td>\n",
       "      <td>0.921264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968147</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.974099</td>\n",
       "      <td>0.920932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968532</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.981766</td>\n",
       "      <td>0.920644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.967583</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.986307</td>\n",
       "      <td>0.920303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.966959</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.969573</td>\n",
       "      <td>0.919922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968728</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.966592</td>\n",
       "      <td>0.919283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968892</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.964960</td>\n",
       "      <td>0.918519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968749</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.967031</td>\n",
       "      <td>0.916828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968133</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.963829</td>\n",
       "      <td>0.914139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.967740</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.953186</td>\n",
       "      <td>0.911057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968032</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.943905</td>\n",
       "      <td>0.907720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968181</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.933435</td>\n",
       "      <td>0.904528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968707</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.941348</td>\n",
       "      <td>0.902680</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.967058</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.926713</td>\n",
       "      <td>0.902668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968746</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>0.944475</td>\n",
       "      <td>0.901906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.965852</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>0.925649</td>\n",
       "      <td>0.901303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968237</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>0.931463</td>\n",
       "      <td>0.900504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.966904</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>0.919571</td>\n",
       "      <td>0.899314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968324</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>0.926155</td>\n",
       "      <td>0.897703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.967089</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>0.921069</td>\n",
       "      <td>0.895970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.967456</td>\n",
       "      <td>0.974746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  val_loss  train_iou   val_iou  train_acc   val_acc\n",
       "0       1    1.190840  1.133607   0.056460  0.043494   0.968877  0.974746\n",
       "1       2    1.164949  1.119090   0.056205  0.044043   0.969616  0.974746\n",
       "2       3    1.128882  1.075146   0.054092  0.040056   0.969139  0.974746\n",
       "3       4    1.094905  1.027226   0.040842  0.022111   0.967611  0.974746\n",
       "4       5    1.054504  0.990963   0.013751  0.003282   0.967917  0.974746\n",
       "5       6    1.024019  0.966123   0.001248  0.000124   0.968186  0.974746\n",
       "6       7    1.013201  0.949408   0.000055  0.000019   0.967312  0.974746\n",
       "7       8    0.994900  0.938894   0.000009       NaN   0.968209  0.974746\n",
       "8       9    0.989056  0.932630   0.000000       NaN   0.968117  0.974746\n",
       "9      10    0.991728  0.928633        NaN       NaN   0.967380  0.974746\n",
       "10     11    0.992222  0.926200        NaN       NaN   0.967071  0.974746\n",
       "11     12    0.977041  0.924447        NaN       NaN   0.968646  0.974746\n",
       "12     13    0.982640  0.923357        NaN       NaN   0.967895  0.974746\n",
       "13     14    0.983979  0.922585        NaN       NaN   0.967659  0.974746\n",
       "14     15    0.979320  0.922015        NaN       NaN   0.968123  0.974746\n",
       "15     16    0.999612  0.921600        NaN       NaN   0.965773  0.974746\n",
       "16     17    0.978220  0.921264        NaN       NaN   0.968147  0.974746\n",
       "17     18    0.974099  0.920932        NaN       NaN   0.968532  0.974746\n",
       "18     19    0.981766  0.920644        NaN       NaN   0.967583  0.974746\n",
       "19     20    0.986307  0.920303        NaN       NaN   0.966959  0.974746\n",
       "20     21    0.969573  0.919922        NaN       NaN   0.968728  0.974746\n",
       "21     22    0.966592  0.919283        NaN       NaN   0.968892  0.974746\n",
       "22     23    0.964960  0.918519        NaN       NaN   0.968749  0.974746\n",
       "23     24    0.967031  0.916828        NaN       NaN   0.968133  0.974746\n",
       "24     25    0.963829  0.914139        NaN       NaN   0.967740  0.974746\n",
       "25     26    0.953186  0.911057        NaN       NaN   0.968032  0.974746\n",
       "26     27    0.943905  0.907720        NaN       NaN   0.968181  0.974746\n",
       "27     28    0.933435  0.904528        NaN       NaN   0.968707  0.974746\n",
       "28     29    0.941348  0.902680        NaN       NaN   0.967058  0.974746\n",
       "29     30    0.926713  0.902668        NaN       NaN   0.968746  0.974746\n",
       "30     31    0.944475  0.901906        NaN       NaN   0.965852  0.974746\n",
       "31     32    0.925649  0.901303        NaN       NaN   0.968237  0.974746\n",
       "32     33    0.931463  0.900504        NaN       NaN   0.966904  0.974746\n",
       "33     34    0.919571  0.899314        NaN       NaN   0.968324  0.974746\n",
       "34     35    0.926155  0.897703        NaN       NaN   0.967089  0.974746\n",
       "35     36    0.921069  0.895970        NaN       NaN   0.967456  0.974746"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6fa8040690>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmokePlumeDataset():\n",
    "    \"\"\"SmokePlume Dataset class.\n",
    "\n",
    "    The image data directory is expected to contain two directories, one labeled\n",
    "    `positive` and one labeled `negative`, containing the corresponding image\n",
    "    files.\n",
    "\n",
    "    The function `create_dataset` can be used as a wrapper to create a\n",
    "    data set.\n",
    "\n",
    "    :param datadir: (str) image directory root, has to contain `negative` and\n",
    "                    `positive` subdirectories, required\n",
    "    :param mult: (int) factor by which to multiply data set size, default=1\n",
    "    :param transform: (`torchvision.transform` object) transformations to be\n",
    "                      applied, default: `None`\n",
    "    :param balance: (str) method for balancing the data set; `'upsample'` the\n",
    "                    smaller of the two classes or `'downsample'` the larger\n",
    "                    of the two. Anything else omits balancing.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, datadir=None, mult=1, transform=None, balance='upsample'):\n",
    "        self.datadir = datadir\n",
    "        self.transform = transform\n",
    "        self.imgfiles = []  # list of image files\n",
    "        self.labels = []    # list of image file labels\n",
    "        self.positive_indices = []  # list of indices for positive examples\n",
    "        self.negative_indices = []  # list of indices for negative examples\n",
    "\n",
    "        # read in image file names\n",
    "        idx = 0\n",
    "        for root, dirs, files in os.walk(datadir):\n",
    "            for filename in files:\n",
    "                if not filename.endswith('.jpg'):\n",
    "                    continue\n",
    "                self.imgfiles.append(os.path.join(root, filename))\n",
    "                if 'positive' in root:\n",
    "                    self.labels.append(True)\n",
    "                    self.positive_indices.append(idx)\n",
    "                    idx += 1\n",
    "                elif 'negative' in root:\n",
    "                    self.labels.append(False)\n",
    "                    self.negative_indices.append(idx)\n",
    "                    idx += 1\n",
    "\n",
    "        # turn lists into arrays\n",
    "        self.imgfiles = np.array(self.imgfiles)\n",
    "        self.labels = np.array(self.labels)\n",
    "        self.positive_indices = np.array(self.positive_indices)\n",
    "        self.negative_indices = np.array(self.negative_indices)\n",
    "\n",
    "        # balance sample, if desired\n",
    "        if balance == 'downsample':\n",
    "            self.balance_downsample()\n",
    "        elif balance == 'upsample':\n",
    "            self.balance_upsample()\n",
    "\n",
    "        # increase data set size by factor `mult`\n",
    "        if mult > 1:\n",
    "            self.imgfiles = np.array([*self.imgfiles] * mult)\n",
    "            self.labels = np.array([*self.labels] * mult)\n",
    "            self.positive_indices = np.array([*self.positive_indices] * mult)\n",
    "            self.negative_indices = np.array([*self.negative_indices] * mult)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns length of data set.\"\"\"\n",
    "        return len(self.imgfiles)\n",
    "\n",
    "    def balance_downsample(self):\n",
    "        \"\"\"Balance data set by downsampling the negative class (which is the larger of the two).\"\"\"\n",
    "        subsample_idc = np.ravel([\n",
    "            self.negative_indices,\n",
    "            self.positive_indices[\n",
    "                np.random.randint(0, len(self.positive_indices),\n",
    "                                  len(self.negative_indices))]]).astype(int)\n",
    "\n",
    "        # adjust other class attributes accordingly\n",
    "        self.imgfiles = self.imgfiles[subsample_idc]\n",
    "        self.labels = self.labels[subsample_idc]\n",
    "        self.positive_indices = np.arange(0, len(self.labels), 1)[\n",
    "            self.labels == True]\n",
    "        self.negative_indices = np.arange(0, len(self.labels), 1)[\n",
    "            self.labels == False]\n",
    "\n",
    "    def balance_upsample(self):\n",
    "        \"\"\"Balance data set by upsampling the positive class (which is the smaller of the two).\"\"\"\n",
    "        subsample_idc = np.ravel([\n",
    "            self.negative_indices[\n",
    "                np.random.randint(0, len(self.negative_indices),\n",
    "                                  len(self.positive_indices)-\n",
    "                                  len(self.negative_indices))]]).astype(int)\n",
    "\n",
    "        # adjust other class attributes accordingly\n",
    "        self.imgfiles = np.concatenate((self.imgfiles,\n",
    "                                        self.imgfiles[subsample_idc]), axis=0)\n",
    "        self.labels = np.concatenate((self.labels,\n",
    "                                      self.labels[subsample_idc]),\n",
    "                                     axis=0)\n",
    "\n",
    "        self.positive_indices = np.arange(0, len(self.labels), 1)[\n",
    "            self.labels == True]\n",
    "        self.negative_indices = np.arange(0, len(self.labels), 1)[\n",
    "            self.labels == False]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Read in image data, preprocess, and apply transformations.\"\"\"\n",
    "        # read in data file\n",
    "        imgfile = rio.open(self.imgfiles[idx])\n",
    "        imgdata = np.array([imgfile.read(i) for i in [1,2,3]])\n",
    "\n",
    "        sample = {\n",
    "            'idx': idx,\n",
    "            'img': imgdata,\n",
    "            'lbl': self.labels[idx],\n",
    "            'imgfile': self.imgfiles[idx]\n",
    "        }\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def display(self, idx, offset=0.2, scaling=1.5):\n",
    "        \"\"\"Display a given example from the data set with index `idx`.\n",
    "\n",
    "        Only RGB channels are displayed.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Image index to be displayed.\n",
    "            offset (float): Constant scaling offset (on a range [0,1]).\n",
    "            scaling (float): Scaling factor.\n",
    "\n",
    "        Returns:\n",
    "            `matplotlib.pyplot.figure` object.\n",
    "        \"\"\"\n",
    "        imgdata = self[idx]['img']\n",
    "\n",
    "        # scale image data\n",
    "        imgdata = offset + scaling * (\n",
    "            np.dstack([imgdata[3], imgdata[2], imgdata[1]]) -\n",
    "            np.min([imgdata[3], imgdata[2], imgdata[1]])) / \\\n",
    "                (np.max([imgdata[3], imgdata[2], imgdata[1]]) -\n",
    "                 np.min([imgdata[3], imgdata[2], imgdata[1]]))\n",
    "\n",
    "        f, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "        ax.imshow((imgdata - np.min(imgdata, axis=(0, 1))) /\n",
    "                  (np.max(imgdata, axis=(0, 1)) -\n",
    "                   np.min(imgdata, axis=(0, 1))))\n",
    "\n",
    "        return f\n",
    "\n",
    "class ToTensor:\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        \"\"\"Convert sample to Tensor.\n",
    "\n",
    "        Args:\n",
    "            sample (dict): Sample to be converted to Tensor.\n",
    "\n",
    "        Returns:\n",
    "            dict: Converted Tensor sample.\n",
    "        \"\"\"\n",
    "        out = {'idx': sample['idx'],\n",
    "               'img': torch.from_numpy(sample['img'].copy()),\n",
    "               'lbl': sample['lbl'],\n",
    "               'imgfile': sample['imgfile']}\n",
    "        return out\n",
    "\n",
    "class Normalize:\n",
    "    \"\"\"Normalize pixel values to zero mean and range [-1, +1] measured in\n",
    "    standard deviations.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.channel_means = np.array(\n",
    "            [809.2, 900.5, 1061.4, 1091.7, 1384.5, 1917.8,\n",
    "             2105.2, 2186.3, 2224.8, 2346.8, 1901.2, 1460.42])\n",
    "        self.channel_stds = np.array(\n",
    "            [441.8, 624.7, 640.8, 718.1, 669.1, 767.5,\n",
    "             843.3, 947.9, 882.4, 813.7, 716.9, 674.8])\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        \"\"\"Normalize the given sample.\n",
    "\n",
    "        Args:\n",
    "            sample (dict): Sample to be normalized.\n",
    "\n",
    "        Returns:\n",
    "            dict: Normalized sample.\n",
    "        \"\"\"\n",
    "        sample['img'] = (sample['img'] - self.channel_means.reshape(\n",
    "            sample['img'].shape[0], 1, 1)) / self.channel_stds.reshape(\n",
    "            sample['img'].shape[0], 1, 1)\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "class Randomize:\n",
    "    \"\"\"Randomize image orientation including rotations by integer multiples of\n",
    "       90 deg, (horizontal) mirroring, and (vertical) flipping.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        \"\"\"Randomly rotate, mirror, and/or flip the given sample.\n",
    "\n",
    "        Args:\n",
    "            sample (dict): Sample to be randomized.\n",
    "\n",
    "        Returns:\n",
    "            dict: Randomized sample.\n",
    "        \"\"\"\n",
    "        imgdata = sample['img']\n",
    "\n",
    "        # mirror horizontally\n",
    "        mirror = np.random.randint(0, 2)\n",
    "        if mirror:\n",
    "            imgdata = np.flip(imgdata, 2)\n",
    "        # flip vertically\n",
    "        flip = np.random.randint(0, 2)\n",
    "        if flip:\n",
    "            imgdata = np.flip(imgdata, 1)\n",
    "        # rotate by [0,1,2,3]*90 deg\n",
    "        rot = np.random.randint(0, 4)\n",
    "        imgdata = np.rot90(imgdata, rot, axes=(1, 2))\n",
    "\n",
    "        return {'idx': sample['idx'],\n",
    "                'img': imgdata.copy(),\n",
    "                'lbl': sample['lbl'],\n",
    "                'imgfile': sample['imgfile']}\n",
    "\n",
    "\n",
    "class RandomCrop:\n",
    "    \"\"\"Randomly crop 90x90 pixel image (from 120x120).\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        \"\"\"Randomly crop a 90x90 pixel region from the given sample.\n",
    "\n",
    "        Args:\n",
    "            sample (dict): Sample to be cropped.\n",
    "\n",
    "        Returns:\n",
    "            dict: Randomized sample.\n",
    "        \"\"\"\n",
    "        imgdata = sample['img']\n",
    "\n",
    "        x, y = np.random.randint(0, 30, 2)\n",
    "\n",
    "        return {'idx': sample['idx'],\n",
    "                'img': imgdata.copy()[:, y:y+90, x:x+90],\n",
    "                'lbl': sample['lbl'],\n",
    "                'imgfile': sample['imgfile']}\n",
    "\n",
    "\n",
    "def create_dataset(*args, apply_transforms=True, **kwargs):\n",
    "    \"\"\"Create a dataset with the given arguments and transformations.\n",
    "\n",
    "    Args:\n",
    "        *args: Arguments for SmokePlumeDataset.\n",
    "        apply_transforms (bool): If True, apply available transformations.\n",
    "        **kwargs: Keyword arguments for SmokePlumeDataset.\n",
    "\n",
    "    Returns:\n",
    "        SmokePlumeDataset: Data set.\n",
    "    \"\"\"\n",
    "    if apply_transforms:\n",
    "        data_transforms = transforms.Compose([\n",
    "            Normalize(),\n",
    "            Randomize(),\n",
    "            ToTensor(),\n",
    "        ])\n",
    "    else:\n",
    "        data_transforms = None\n",
    "\n",
    "    data = SmokePlumeDataset(*args, **kwargs, transform=data_transforms)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet_pretrained = resnet50(pretrained=True)\n",
    "        self.resnet_pretrained.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3),\n",
    "                              stride=(2, 2),padding=(3, 3), bias=False)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.resnet_pretrained.fc.out_features, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, image):\n",
    "        img_features = self.resnet_pretrained(image)\n",
    "        img_features = torch.flatten(img_features, 1)\n",
    "        img_features = self.fc1(img_features)\n",
    "        x = self.relu(img_features)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "# Create datasets\n",
    "data_train = create_dataset(datadir=\"../train_jpg\", mult=1)\n",
    "data_test = create_dataset(datadir=\"../test_jpg\", mult=1)\n",
    "\n",
    "# Initialize data loaders\n",
    "train_dl = DataLoader(data_train, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "test_dl = DataLoader(data_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, opt, loss, epoch):\n",
    "    model.train()\n",
    "    train_loss_total, train_acc_total = 0, 0\n",
    "    # train_score_total, train_label_total, train_pred_total = [], [], []\n",
    "    progress = tqdm(enumerate(train_dl), desc=\"Train Loss: \", total=len(train_dl))\n",
    "    \n",
    "    for i, batch in progress:\n",
    "        x = batch['img'].float().to(device)\n",
    "        y = batch['lbl'].float().to(device)\n",
    "        output = model(x)\n",
    "\n",
    "        # Derive binary output\n",
    "        output_binary = np.zeros(output.shape)\n",
    "        output_binary[output.cpu().detach().numpy() >= 0] = 1\n",
    "\n",
    "        # Derive accuracy score\n",
    "        label = y.cpu().detach().numpy()\n",
    "        acc = accuracy_score(label, output_binary)\n",
    "        train_acc_total += acc\n",
    "\n",
    "        # Calculate loss\n",
    "        loss_epoch = loss(output, y.reshape(-1, 1))\n",
    "        train_loss_total += loss_epoch.item()\n",
    "        progress.set_description(\"Train Loss: {:.4f}\".format(train_loss_total / (i + 1)))\n",
    "\n",
    "        # Learning\n",
    "        opt.zero_grad()\n",
    "        loss_epoch.backward()\n",
    "        opt.step()\n",
    "    return train_loss_total, train_acc_total, i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loss, opt, epoch):\n",
    "    model.eval()\n",
    "\n",
    "    test_loss_total, test_acc_total = 0, 0\n",
    "    test_label_total, test_pred_total = [], []\n",
    "    progress = tqdm(enumerate(test_dl), total=len(test_dl))\n",
    "\n",
    "    for k, batch in progress:\n",
    "        x, y = batch['img'].float().to(device), batch['lbl'].float().to(device)\n",
    "        output = model(x)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss_epoch = loss(output, y.reshape(-1, 1))\n",
    "        test_loss_total += loss_epoch.item()\n",
    "        progress.set_description(\"Test Loss: {:.4f}\".format(test_loss_total / (k + 1)))\n",
    "\n",
    "        # Derive binary output\n",
    "        output_binary = np.zeros(output.shape)\n",
    "        output_binary[output.cpu().detach().numpy() >= 0] = 1\n",
    "        label = y.cpu().detach().numpy()\n",
    "\n",
    "        test_pred_total += list(output_binary[:, 0])\n",
    "        test_label_total += list(label)\n",
    "\n",
    "        # Derive accuracy score\n",
    "        acc = accuracy_score(y.cpu().detach().numpy(), output_binary)\n",
    "        test_acc_total += acc\n",
    "    return test_loss_total, test_acc_total, test_label_total, test_pred_total, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs, opt, loss, batch_size):\n",
    "    \"\"\"Wrapper function for model training.\n",
    "\n",
    "    :param model: model instance\n",
    "    :param epochs: (int) number of epochs to be trained\n",
    "    :param opt: optimizer instance\n",
    "    :param loss: loss function instance\n",
    "    :param batch_size: (int) batch size\"\"\"\n",
    "    \n",
    "    loss_train, loss_test, train_acc,test_acc =[],[],[],[]\n",
    "    epoch_table = pd.DataFrame()\n",
    "    # Create datasets\n",
    "    data_train = create_dataset(datadir=\"../train_jpg\", mult=1)\n",
    "    data_test = create_dataset(datadir=\"../test_jpg\", mult=1)\n",
    "\n",
    "    # Initialize data loaders\n",
    "    train_dl = DataLoader(data_train, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "    test_dl = DataLoader(data_test, batch_size=batch_size)\n",
    "\n",
    "    # Start training process\n",
    "    test_loss_total_list, test_acc_total_list = [], []\n",
    "    epoch_list = []\n",
    "    for epoch in range(epochs):\n",
    "        epoch_list.append(epoch)\n",
    "        #Training \n",
    "        train_loss_total, train_acc_total, i = train(model, opt, loss, epoch)\n",
    "            \n",
    "        # Logging\n",
    "        writer.add_scalar(\"training loss\", train_loss_total / (i + 1), epoch)\n",
    "        writer.add_scalar(\"training acc\", train_acc_total / (i + 1), epoch)\n",
    "        writer.add_scalar('learning_rate', opt.param_groups[0]['lr'], epoch)\n",
    "        test_loss_total_list.append(train_loss_total / (i + 1))\n",
    "        test_acc_total_list.append(train_acc_total / (i + 1))\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Test\n",
    "        test_loss_total, test_acc_total, test_label_total, test_pred_total, k = test(model, loss, opt, epoch)\n",
    "        \n",
    "        # Logging\n",
    "        writer.add_scalar(\"test loss\", test_loss_total / (k + 1), epoch)\n",
    "        writer.add_scalar(\"test accuracy\", test_acc_total / (k + 1), epoch)\n",
    "        test_loss_total_list.append(test_loss_total / (k + 1))\n",
    "        test_acc_total_list.append(test_acc_total / (k + 1))\n",
    "\n",
    "        # Generate confusion matrix\n",
    "        if epoch == epochs - 1:\n",
    "            array = confusion_matrix(np.array(test_label_total), np.array(test_pred_total))\n",
    "            cm = pd.DataFrame(array, range(2), range(2))\n",
    "            svm = sn.heatmap(cm, annot=True)\n",
    "            figure = svm.get_figure()\n",
    "            image_dir = \"../images/test\"\n",
    "            figure.savefig(f\"{image_dir}/conf_matrix.png\")\n",
    "\n",
    "        # Screen output\n",
    "        print((\"Epoch {:d}: train loss={:.3f}, test loss= {:.3f}, \"\n",
    "               \"train acc={:.3f}, test acc={:.3f}\").format(\n",
    "                   epoch + 1, train_loss_total / (i + 1), test_loss_total / (k + 1),\n",
    "                   train_acc_total / (i + 1), test_acc_total / (k + 1)))\n",
    "\n",
    "        loss_train.append(train_loss_total / (i + 1))\n",
    "        loss_test.append(test_loss_total / (k + 1))\n",
    "        train_acc.append(train_acc_total / (i + 1))\n",
    "        test_acc.append(test_acc_total / (k + 1))\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        \n",
    "        \n",
    "    epoch_table['epoch'] = epoch_list\n",
    "    epoch_table[\"training loss\"] = train_loss_total_list\n",
    "    epoch_table[\"training accuracy\"] = train_acc_total_list\n",
    "    epoch_table[\"test loss\"] = test_loss_total_list\n",
    "    epoch_table[\"test accuracy\"] = test_acc_total_list\n",
    "\n",
    "    return model, epoch_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup argument parser\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-f')\n",
    "parser.add_argument('-ep', type=int, default=100, help='Number of epochs')\n",
    "parser.add_argument('-bs', type=int, default=16, help='Batch size')\n",
    "parser.add_argument('-lr', type=float, default=0.003, help='Learning rate')\n",
    "parser.add_argument('-mo', type=float, default=0.7, help='Momentum')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# initialize tensorboard writer\n",
    "writer = SummaryWriter('runs/' + \"ep{}_lr{:.0e}_bs{:03d}_mo{:.1f}/\".format(\n",
    "    args.ep, args.lr, args.bs, args.mo))\n",
    "\n",
    "# initialize loss, optimizer, and scheduler\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.mo)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',\n",
    "                                                factor=0.5, threshold=1e-4,\n",
    "                                                min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# run model training\n",
    "start = time.time()\n",
    "trained_model, epoch_table = train_model(model, args.ep, optimizer, loss, args.bs)\n",
    "end = time.time()\n",
    "print(\"Time taken:\", end - start)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 'epoch' column as index\n",
    "epoch_table = epoch_table.set_index(\"epoch\")\n",
    "\n",
    "# Convert training and test accuracy values to percentages\n",
    "epoch_table['training accuracy'] = epoch_table['training accuracy']*100\n",
    "epoch_table['test accuracy'] = epoch_table['test accuracy']*100\n",
    "\n",
    "# Round all values in the DataFrame to two decimal places\n",
    "epoch_table = epoch_table.apply(lambda x: round(x, 2))\n",
    "\n",
    "# Visualize the table\n",
    "epoch_table.style.background_gradient(cmap='Blues').set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and testing accuracy\n",
    "epoch_table_acc = epoch_table[['training accuracy','test accuracy']]\n",
    "acc_plot = sns.relplot(data=epoch_table_acc, kind=\"line\")\n",
    "acc_plot.set(ylabel=\"accuracy\",title = \"Training and testing accuracy\")\n",
    "plt.savefig(\"accuracy.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and testing loss\n",
    "epoch_table_loss = epoch_table[['training loss','test loss']]\n",
    "acc_plot = sns.relplot(data=epoch_table_loss, kind=\"line\")\n",
    "acc_plot.set(ylabel=\"loss\",title = \"Training and testing loss\")\n",
    "plt.savefig(\"loss.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
